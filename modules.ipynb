{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-08-19T15:13:58.543011Z",
     "start_time": "2025-08-19T15:13:58.530727Z"
    }
   },
   "outputs": [],
   "source": [
    "import torch \n",
    "import torch.nn as nn\n",
    "from torchsummary import summary\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "outputs": [],
   "source": [
    "device = torch.device('mps')\n",
    "torch.set_default_device(device=device)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-08-19T17:48:40.143959Z",
     "start_time": "2025-08-19T17:48:40.128647Z"
    }
   },
   "id": "79e5dfdba7ff37e0"
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "outputs": [
    {
     "data": {
      "text/plain": "device(type='cpu')"
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.get_default_device()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-08-19T17:48:40.515483Z",
     "start_time": "2025-08-19T17:48:40.509428Z"
    }
   },
   "id": "58e395dd5053869c"
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Loss functions\n",
    "- For this code to reach optimal performance we need 2 losses that we will combine \n",
    "- One of them is Dice Loss and the other is Focal loss \n",
    "- Dice loss handles class imbalance \n",
    "- Focal loss does other stuff \n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "b5894f7d29536267"
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Focal Loss "
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "a7f73c12e828e8b"
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "outputs": [],
   "source": [
    "class FocalLoss(nn.Module):\n",
    "    def __init__(self, gamma=2, alpha=None, reduction='mean', task_type='mutli-class', num_classes=5):\n",
    "        \"\"\"\n",
    "        Unified Focal Loss class for binary, multi-class, and multi-label classification tasks.\n",
    "        :param gamma: Focusing parameter, controls the strength of the modulating factor (1 - p_t)^gamma\n",
    "        :param alpha: Balancing factor, can be a scalar or a tensor for class-wise weights. If None, no class balancing is used.\n",
    "        :param reduction: Specifies the reduction method: 'none' | 'mean' | 'sum'\n",
    "        :param task_type: Specifies the type of task: 'binary', 'multi-class', or 'multi-label'\n",
    "        :param num_classes: Number of classes (only required for multi-class classification)\n",
    "        \"\"\"\n",
    "        super(FocalLoss, self).__init__()\n",
    "        self.gamma = gamma\n",
    "        self.alpha = alpha\n",
    "        self.reduction = reduction\n",
    "        self.task_type = task_type\n",
    "        self.num_classes = num_classes\n",
    "\n",
    "        # Handle alpha for class balancing in multi-class tasks\n",
    "        if task_type == 'multi-class' and alpha is not None and isinstance(alpha, (list, torch.Tensor)):\n",
    "            assert num_classes is not None, \"num_classes must be specified for multi-class classification\"\n",
    "            if isinstance(alpha, list):\n",
    "                self.alpha = torch.Tensor(alpha)\n",
    "            else:\n",
    "                self.alpha = alpha\n",
    "\n",
    "    def forward(self, inputs, targets):\n",
    "        \"\"\"\n",
    "        Forward pass to compute the Focal Loss based on the specified task type.\n",
    "        :param inputs: Predictions (logits) from the model.\n",
    "                       Shape:\n",
    "                         - binary/multi-label: (batch_size, num_classes)\n",
    "                         - multi-class: (batch_size, num_classes)\n",
    "        :param targets: Ground truth labels.\n",
    "                        Shape:\n",
    "                         - binary: (batch_size,)\n",
    "                         - multi-label: (batch_size, num_classes)\n",
    "                         - multi-class: (batch_size,)\n",
    "        \"\"\"\n",
    "        if self.task_type == 'binary':\n",
    "            return self.binary_focal_loss(inputs, targets)\n",
    "        elif self.task_type == 'multi-class':\n",
    "            return self.multi_class_focal_loss(inputs, targets)\n",
    "        elif self.task_type == 'multi-label':\n",
    "            return self.multi_label_focal_loss(inputs, targets)\n",
    "        else:\n",
    "            raise ValueError(\n",
    "                f\"Unsupported task_type '{self.task_type}'. Use 'binary', 'multi-class', or 'multi-label'.\")\n",
    "\n",
    "    def binary_focal_loss(self, inputs, targets):\n",
    "        \"\"\" Focal loss for binary classification. \"\"\"\n",
    "        probs = torch.sigmoid(inputs)\n",
    "        targets = targets.float()\n",
    "\n",
    "        # Compute binary cross entropy\n",
    "        bce_loss = F.binary_cross_entropy_with_logits(inputs, targets, reduction='none')\n",
    "\n",
    "        # Compute focal weight\n",
    "        p_t = probs * targets + (1 - probs) * (1 - targets)\n",
    "        focal_weight = (1 - p_t) ** self.gamma\n",
    "\n",
    "        # Apply alpha if provided\n",
    "        if self.alpha is not None:\n",
    "            alpha_t = self.alpha * targets + (1 - self.alpha) * (1 - targets)\n",
    "            bce_loss = alpha_t * bce_loss\n",
    "\n",
    "        # Apply focal loss weighting\n",
    "        loss = focal_weight * bce_loss\n",
    "\n",
    "        if self.reduction == 'mean':\n",
    "            return loss.mean()\n",
    "        elif self.reduction == 'sum':\n",
    "            return loss.sum()\n",
    "        return loss\n",
    "\n",
    "    def multi_class_focal_loss(self, inputs, targets):\n",
    "        \"\"\" Focal loss for multi-class classification. \"\"\"\n",
    "        if self.alpha is not None:\n",
    "            alpha = self.alpha.to(inputs.device)\n",
    "\n",
    "        # Convert logits to probabilities with softmax\n",
    "        probs = F.softmax(inputs, dim=1)\n",
    "\n",
    "        # One-hot encode the targets\n",
    "        targets_one_hot = F.one_hot(targets, num_classes=self.num_classes).float()\n",
    "\n",
    "        # Compute cross-entropy for each class\n",
    "        ce_loss = -targets_one_hot * torch.log(probs)\n",
    "\n",
    "        # Compute focal weight\n",
    "        p_t = torch.sum(probs * targets_one_hot, dim=1)  # p_t for each sample\n",
    "        focal_weight = (1 - p_t) ** self.gamma\n",
    "\n",
    "        # Apply alpha if provided (per-class weighting)\n",
    "        if self.alpha is not None:\n",
    "            alpha_t = alpha.gather(0, targets)\n",
    "            ce_loss = alpha_t.unsqueeze(1) * ce_loss\n",
    "\n",
    "        # Apply focal loss weight\n",
    "        loss = focal_weight.unsqueeze(1) * ce_loss\n",
    "\n",
    "        if self.reduction == 'mean':\n",
    "            return loss.mean()\n",
    "        elif self.reduction == 'sum':\n",
    "            return loss.sum()\n",
    "        return loss\n",
    "\n",
    "    def multi_label_focal_loss(self, inputs, targets):\n",
    "        \"\"\" Focal loss for multi-label classification. \"\"\"\n",
    "        probs = torch.sigmoid(inputs)\n",
    "\n",
    "        # Compute binary cross entropy\n",
    "        bce_loss = F.binary_cross_entropy_with_logits(inputs, targets, reduction='none')\n",
    "\n",
    "        # Compute focal weight\n",
    "        p_t = probs * targets + (1 - probs) * (1 - targets)\n",
    "        focal_weight = (1 - p_t) ** self.gamma\n",
    "\n",
    "        # Apply alpha if provided\n",
    "        if self.alpha is not None:\n",
    "            alpha_t = self.alpha * targets + (1 - self.alpha) * (1 - targets)\n",
    "            bce_loss = alpha_t * bce_loss\n",
    "\n",
    "        # Apply focal loss weight\n",
    "        loss = focal_weight * bce_loss\n",
    "\n",
    "        if self.reduction == 'mean':\n",
    "            return loss.mean()\n",
    "        elif self.reduction == 'sum':\n",
    "            return loss.sum()\n",
    "        return loss"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-08-18T03:27:58.068987Z",
     "start_time": "2025-08-18T03:27:58.066357Z"
    }
   },
   "id": "a573251a4d22911c"
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Dice Loss "
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "41272afa9bd6e3e9"
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "outputs": [],
   "source": [
    "def DiceLoss(pred, target):\n",
    "    \"\"\"This definition generalize to real valued pred and target vector.\n",
    "    This should be differentiable.\n",
    "    pred: tensor with first dimension as batch\n",
    "    target: tensor with first dimension as batch\n",
    "    \"\"\"\n",
    "\n",
    "    smooth = 1.\n",
    "\n",
    "    # have to use contiguous since they may from a torch.view op\n",
    "    iflat = pred.contiguous().view(-1)\n",
    "    tflat = target.contiguous().view(-1)\n",
    "    intersection = (iflat * tflat).sum()\n",
    "\n",
    "    A_sum = torch.sum(tflat * iflat)\n",
    "    B_sum = torch.sum(tflat * tflat)\n",
    "\n",
    "    return 1 - ((2. * intersection + smooth) / (A_sum + B_sum + smooth) )"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-08-18T03:28:53.695171Z",
     "start_time": "2025-08-18T03:28:53.684568Z"
    }
   },
   "id": "f7d63d25e3694f20"
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Modules \n",
    "- We create all the necessary modules for unet to work \n",
    "- these include an Attention block (class) to be used in between the big decoder functions \n",
    "- a self attention block (class) that will be used to calculate the self attention \n",
    "- This will be used only for the final layer in the unet\n",
    "- a double convolutional block - consisting of 2 conv encoders \n",
    "- an output conv block, that takes in the n_dim, h, w image and converts it to n_class, h, w image (final conv layer) \n",
    "- a down class that dictates the flow of the downward convolution (in this case the encoder section)\n",
    "- an up class that dictates the flow of the upward convolution (or conv transpose) (in this case the decoder section)  "
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "4bb717a6e73d9407"
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Class Double conv \n",
    "- A class that has the double convolutional section that is instrumental to the unet encoder and decoder architecture \n",
    "- we set bias to false because batchnorm has its own bias so double the bias is useless\n",
    "- `nn.Conv2d(in, out, kernel = 3, padding = 1, bias=False)` lets say the input is in x h x w \n",
    "- The output would be out x h x w (in this case)... \n",
    "- The general formula = `(h - kernel + 2p) / stride + 1 = h when stride = 1 (default)` \n",
    "- In this case the output and input shape are the same but the number of filters keeps changing. \n",
    "- Usually we want to reduce the filter count for every conv block  "
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "8d69681c7c8a4616"
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [],
   "source": [
    "class DoubleConv(nn.Module): \n",
    "    def __init__(self, in_channel, out_channel, mid_channels = None, bias = False):\n",
    "        super().__init__()\n",
    "        if not mid_channels: \n",
    "            mid_channels = out_channel\n",
    "        self.doubleconv = nn.Sequential(\n",
    "            # first convolutional layer\n",
    "            nn.Conv2d(in_channels= in_channel, out_channels= mid_channels, padding= 1, kernel_size= 3, bias= bias),\n",
    "            nn.BatchNorm2d(mid_channels), \n",
    "            nn.ReLU(inplace=True), \n",
    "            \n",
    "            # Second convolutional layer\n",
    "            nn.Conv2d(in_channels=mid_channels, out_channels=out_channel, padding=1, kernel_size=3, bias= bias),\n",
    "            nn.BatchNorm2d(out_channel),\n",
    "            nn.ReLU(inplace=True),\n",
    "        ) \n",
    "        \n",
    "    def forward(self, x):\n",
    "        return self.doubleconv(x)\n",
    "    "
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-08-19T15:14:04.176764Z",
     "start_time": "2025-08-19T15:14:04.170050Z"
    }
   },
   "id": "709f55dcaad2825c"
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Class Down \n",
    "- This is the class used to facilitate the encoder class\n",
    "- At the moment, after the encoder we only need to run the maxpool2d after it  \n",
    "- So we run the doubleconv layer in the down class and then run the maxpool2D after this \n",
    "- Return the maxpool output for the next down layer \n",
    "- Return the encoder output for the attention layer "
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "afded93dc21af9e6"
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [],
   "source": [
    "class Down(nn.Module): \n",
    "    def __init__(self, in_channel, out_channel):\n",
    "        super().__init__()\n",
    "        self.in_channel = in_channel\n",
    "        self.out_channel = out_channel\n",
    "        self.maxpool_layer = nn.MaxPool2d(kernel_size= 2)\n",
    "        \n",
    "        \n",
    "    def forward(self, x):\n",
    "        feat = DoubleConv(in_channel=self.in_channel, out_channel=self.out_channel)(x)\n",
    "        return self.maxpool_layer(feat) # return the maxpool output and the encoder output  \n",
    "    "
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-08-19T15:14:04.706298Z",
     "start_time": "2025-08-19T15:14:04.702823Z"
    }
   },
   "id": "fa8fb8696184f3f2"
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Self Attention block \n",
    "- Self attention of each encoder level \n",
    "- A lot of computation required "
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "211311ffafc723b1"
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Query value and key calculations \n",
    "- First to calculate attention \n",
    "- Attention = query x key \n",
    "- Our query is of the shape -> `batch_size, Channels, W, H` \n",
    "- Flatten it to -> `Batch_size, Channels, H*W` (channels is in_dim // 8)  \n",
    "- Key is also of the shape -> `batch_size, Channels, H*W` (Channels is in_dim // 8) \n",
    "- Flatten Key -> `batch_size, channels, H*W`\n",
    "- Torch.batch matrix multiplication -> `Query * key` = attention at batch level \n",
    "- To perform this batch level multiplication convert query dim to Batch_size, N, Channels \n",
    "- Attention -> `Batch_size, N, N`   \n",
    "- REMEMBER THAT ATTENTION NEEDS A SOFTMAX AT THE END\n",
    "- Now sum (attention * value) is what we need (this is essentially a V * A^T\n",
    "- Value -> `B x 64 x N` Attention permute to -> `B x N x N` (This is essentially a transpose)    \n",
    "- In matrix form that becomes `torch.bmm(value, attention.T)` (The T is only for N x N not the batch)\n",
    "- You can use `nn.permute(0,2,1)` to do that"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "bce05aec817ba44f"
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [],
   "source": [
    "class SelfAttention(nn.Module): \n",
    "    def __init__(self, in_dim):\n",
    "        super().__init__()\n",
    "        self.channel = in_dim\n",
    "        \n",
    "        self.query_conv = nn.Conv2d(in_channels= in_dim, out_channels= in_dim // 8, kernel_size= 1)\n",
    "        self.key_conv = nn.Conv2d(in_channels= in_dim, out_channels= in_dim // 8, kernel_size= 1)\n",
    "        self.value_conv = nn.Conv2d(in_channels= in_dim, out_channels= in_dim, kernel_size= 1)\n",
    "        \n",
    "        self.gamma = nn.Parameter(torch.zeros(1))\n",
    "        \n",
    "    def forward(self, x):\n",
    "        batch_size, C, width, height = x.size()\n",
    "        # this is essentially query transpose without touching the batch \n",
    "        query_projection = self.query_conv(x).view(batch_size, -1, width* height).permute(0,2,1)\n",
    "        key_projection = self.key_conv(x).view(batch_size, -1, width* height)\n",
    "        \n",
    "        # energy calculation -> energy is just attention before softmax\n",
    "        energy = torch.bmm(query_projection, key_projection)\n",
    "        attention = torch.softmax(energy, dim= -1)\n",
    "        \n",
    "        # Calculate Value projection \n",
    "        value_projection = self.value_conv(x).view(batch_size, -1, width* height)\n",
    "        \n",
    "        # calculate self attention mask \n",
    "        out = torch.bmm(value_projection, attention.permute(0,2,1))\n",
    "        \n",
    "        # reshape mask to fit width, height \n",
    "        out = out.view(batch_size, C, width, height)\n",
    "        \n",
    "        # gamma stuff \n",
    "        out = self.gamma * out + x\n",
    "        \n",
    "        return out#, attention\n",
    "        "
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-08-19T15:14:06.567331Z",
     "start_time": "2025-08-19T15:14:06.562325Z"
    }
   },
   "id": "4a16fe839a566f86"
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Attention Block \n",
    "- gate (g) = decoder feature - f_g channel count of decoder  \n",
    "- x (skip) = encoder level - f_x channel count of skip level encoder \n",
    "- F_int = reduced channel count which is f_x // 2\n",
    "- weight of g => a conv block f_g to f_int with kernel, stride = 1, padding =0, bias = False (because batchnorm is true)\n",
    "- Same for x\n",
    "- Add the conv x and conv g with a relu  \n",
    "- a conv layer f_int to 1 \n",
    "- batch norm then sigmoid "
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "4f2f6bb02c3038cc"
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [],
   "source": [
    "class Attention_block(nn.Module): \n",
    "    def __init__(self, encoder_channels, decoder_channels, intermediate_channels = None):\n",
    "        super().__init__()\n",
    "        if not intermediate_channels: \n",
    "            intermediate_channels = decoder_channels // 2\n",
    "        \n",
    "        self.W_gate = nn.Sequential(\n",
    "            nn.Conv2d(in_channels= decoder_channels, out_channels= intermediate_channels, kernel_size= 1, stride=1, padding= 0),\n",
    "            nn.BatchNorm2d(intermediate_channels),\n",
    "        )\n",
    "        \n",
    "        self.W_encoder = nn.Sequential(\n",
    "            nn.Conv2d(in_channels= encoder_channels, out_channels= intermediate_channels, kernel_size= 1, stride= 1, padding= 0),\n",
    "            nn.BatchNorm2d(intermediate_channels),\n",
    "        )\n",
    "        \n",
    "        self.psi = nn.Sequential(\n",
    "            nn.Conv2d(in_channels= intermediate_channels, out_channels= 1, kernel_size= 1, stride = 1, padding= 0),\n",
    "            nn.Sigmoid(),\n",
    "        )\n",
    "        \n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "        \n",
    "    def forward(self, enc, dec):\n",
    "        dec_conv = self.W_gate(dec)\n",
    "        enc_conv = self.W_encoder(enc)\n",
    "        \n",
    "        psi = self.relu(dec_conv + enc_conv)\n",
    "        psi = self.psi(psi)\n",
    "        \n",
    "        return enc * psi\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-08-19T15:14:07.823199Z",
     "start_time": "2025-08-19T15:14:07.818553Z"
    }
   },
   "id": "565777b24e30f6cd"
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Up function  \n",
    "- This is the up function for the Unets - common "
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "859ba2c92741339"
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "outputs": [],
   "source": [
    "class Decoder_up(nn.Module): \n",
    "    def __init__(self, in_channel, out_channel):\n",
    "        super().__init__()\n",
    "        self.up = nn.Sequential(\n",
    "            nn.Upsample(scale_factor=2, mode= 'bilinear', align_corners= True),\n",
    "            DoubleConv(in_channel=in_channel, out_channel=out_channel),\n",
    "        )\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.up(x)\n",
    "        return x\n",
    "        "
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-08-19T15:26:36.148558Z",
     "start_time": "2025-08-19T15:26:36.142108Z"
    }
   },
   "id": "e31fc4dc8440a801"
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Out convolutional Layer \n",
    "- THe final convolutional layer "
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "4a75e53cdb04148"
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "outputs": [],
   "source": [
    "class outConv(nn.Module): \n",
    "    def __init__(self, in_channel, out_channel):\n",
    "        super().__init__()\n",
    "        self.conv = nn.Conv2d(in_channels= in_channel, out_channels= out_channel, kernel_size=1)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        return self.conv(x)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-08-19T15:14:11.381480Z",
     "start_time": "2025-08-19T15:14:11.378107Z"
    }
   },
   "id": "5a2af5e80dec818b"
  },
  {
   "cell_type": "markdown",
   "source": [
    "# UNET class \n",
    "- Use the above functions to code a unet with attention \n",
    "- Down class for the encoder\n",
    "- Up class for the decoder\n",
    "- attention block class to calculate attention \n",
    "- worry about self attention later  "
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "d40ce40876ca6c98"
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Encoder Class\n",
    "- Unet has 4 encoder channels, 4 double conv blocks that is (in our code the class called down)\n",
    "- first block = 3 -> 64 (3 channels to 64 channels {64 filters})\n",
    "- Second block = 64 -> 128\n",
    "- Third block = 128 -> 256 \n",
    "- Fourth block = 256 -> 512\n",
    "- Fifth block = 512 -> 1024 `CODE BLOCK`"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "1571b623b780ed74"
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Self Attention block - NOT IMPLEMENTED YET \n",
    "- Here we use the self attention block to calculate self attention at the code layer  \n",
    "- We can technically expand self attention to all the layers but it is extremely memory intensive and only needed for like really clean datasets "
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "bab63d6811d734b3"
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Decoder Layer \n",
    "- This layer is also known as the class up in our code. \n",
    "- Takes the encoded image and decodes. \n",
    "- While it decodes we will feed it attention masked skip encoder values \n",
    "- This is done using the attention block function, returns the mask \n",
    "- Each block reduces the filter count \n",
    "- upconv1 => 512 in channels -> 256 out channels \n",
    "- upconv2 => 256 in channels -> 128 out channels\n",
    "- upconv3 => 128 in channels -> 64 out channels \n",
    "- upconv4 => 64 out channels -> `n_classes` out channels \n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "ce16d9b87a90b818"
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### NOTE \n",
    "taking an argument for the mid class layers might make this code more changeable "
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "c215a9f81d9635aa"
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "outputs": [],
   "source": [
    "class Self_Attention_Unet(nn.Module):\n",
    "    def __init__(\n",
    "            self,\n",
    "            image_channels,\n",
    "            n_classes,\n",
    "            mid_layers = [64,128, 256, 512, 1024],\n",
    "            bilinear= True,\n",
    "    ):\n",
    "        super().__init__()\n",
    "\n",
    "\n",
    "\n",
    "        # Encoder section of the network\n",
    "        \n",
    "        self.down1 = DoubleConv(image_channels, mid_layers[0])\n",
    "        self.down2 = Down(mid_layers[0], mid_layers[1])\n",
    "        self.down3 = Down(mid_layers[1], mid_layers[2])\n",
    "        self.down4 = Down(mid_layers[2], mid_layers[3])\n",
    "\n",
    "        # calculate all the self attention values \n",
    "        self.attention1 = SelfAttention(mid_layers[0])\n",
    "        self.attention2 = SelfAttention(mid_layers[1])\n",
    "        self.attention3 = SelfAttention(mid_layers[2])\n",
    "        self.attention4 = SelfAttention(mid_layers[3])\n",
    "\n",
    "\n",
    "        # code block \n",
    "        self.down_code = Down(mid_layers[3], mid_layers[4])\n",
    "\n",
    "        # self attention \n",
    "        # ADD SELF ATTENTION for code layer \n",
    "\n",
    "\n",
    "\n",
    "        # decoder block\n",
    "\n",
    "        self.up4 = Decoder_up(mid_layers[4], mid_layers[3]) # code block \n",
    "        self.up_conv4 = DoubleConv(in_channel= mid_layers[4], out_channel= mid_layers[3])\n",
    "        \n",
    "        self.up3 = Decoder_up(mid_layers[3], mid_layers[2])\n",
    "        self.up_conv3 = DoubleConv(in_channel= mid_layers[3], out_channel= mid_layers[2])\n",
    "        \n",
    "        self.up2 = Decoder_up(mid_layers[2], mid_layers[1])\n",
    "        self.up_conv2 = DoubleConv(in_channel= mid_layers[2], out_channel= mid_layers[1])\n",
    "        \n",
    "        self.up1 = Decoder_up(mid_layers[1], mid_layers[0])\n",
    "        self.up_conv1 = DoubleConv(in_channel= mid_layers[1], out_channel= mid_layers[0])\n",
    "\n",
    "\n",
    "        # outputlayers\n",
    "        self.outc = outConv(mid_layers[0], n_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # you cant create a seperate encoder, decoder function because you need the x1, x2 and so on values for attention calculation   \n",
    "        # encoder calculations \n",
    "        x1 = self.down1(x)\n",
    "        x2 = self.down2(x1)\n",
    "        x3 = self.down3(x2)\n",
    "        x4 = self.down4(x3)\n",
    "        x5 = self.down_code(x4)\n",
    "\n",
    "        # x5 is the code layer\n",
    "\n",
    "        # calculate attention\n",
    "\n",
    "        v1 = self.attention1(x1)\n",
    "        v2 = self.attention2(x2)\n",
    "        v3 = self.attention3(x3)\n",
    "        v4 = self.attention4(x4)\n",
    "\n",
    "        dec_out = self.up4(x5) \n",
    "        dec_out = torch.cat((dec_out, v4), dim=1)\n",
    "        dec_out = self.up_conv4(dec_out)\n",
    "\n",
    "        dec_out= self.up3(dec_out)\n",
    "        dec_out = torch.cat((dec_out, v3), dim=1)\n",
    "        dec_out = self.up_conv3(dec_out)\n",
    "\n",
    "        dec_out = self.up2(dec_out)\n",
    "        dec_out = torch.cat((dec_out, v2), dim=1)\n",
    "        dec_out = self.up_conv2(dec_out)\n",
    "\n",
    "        dec_out = self.up1(dec_out)\n",
    "        dec_out = torch.cat((dec_out, v1), dim=1)\n",
    "        dec_out = self.up_conv1(dec_out)\n",
    "\n",
    "        # calculate output\n",
    "        logits = self.outc(dec_out)\n",
    "        return logits\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-08-19T17:49:25.977537Z",
     "start_time": "2025-08-19T17:49:25.967653Z"
    }
   },
   "id": "509b68613f01df71"
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "outputs": [
    {
     "data": {
      "text/plain": "Self_Attention_Unet2(\n  (down1): DoubleConv(\n    (doubleconv): Sequential(\n      (0): Conv2d(6, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (2): ReLU(inplace=True)\n      (3): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (4): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (5): ReLU(inplace=True)\n    )\n  )\n  (down2): Down(\n    (maxpool_layer): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n  )\n  (down3): Down(\n    (maxpool_layer): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n  )\n  (down4): Down(\n    (maxpool_layer): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n  )\n  (attention1): SelfAttention(\n    (query_conv): Conv2d(64, 8, kernel_size=(1, 1), stride=(1, 1))\n    (key_conv): Conv2d(64, 8, kernel_size=(1, 1), stride=(1, 1))\n    (value_conv): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1))\n  )\n  (attention2): SelfAttention(\n    (query_conv): Conv2d(128, 16, kernel_size=(1, 1), stride=(1, 1))\n    (key_conv): Conv2d(128, 16, kernel_size=(1, 1), stride=(1, 1))\n    (value_conv): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1))\n  )\n  (attention3): SelfAttention(\n    (query_conv): Conv2d(256, 32, kernel_size=(1, 1), stride=(1, 1))\n    (key_conv): Conv2d(256, 32, kernel_size=(1, 1), stride=(1, 1))\n    (value_conv): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))\n  )\n  (attention4): SelfAttention(\n    (query_conv): Conv2d(512, 64, kernel_size=(1, 1), stride=(1, 1))\n    (key_conv): Conv2d(512, 64, kernel_size=(1, 1), stride=(1, 1))\n    (value_conv): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1))\n  )\n  (down_code): Down(\n    (maxpool_layer): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n  )\n  (up4): Decoder_up(\n    (up): Sequential(\n      (0): Upsample(scale_factor=2.0, mode='bilinear')\n      (1): DoubleConv(\n        (doubleconv): Sequential(\n          (0): Conv2d(1024, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n          (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n          (2): ReLU(inplace=True)\n          (3): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n          (4): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n          (5): ReLU(inplace=True)\n        )\n      )\n    )\n  )\n  (up_conv4): DoubleConv(\n    (doubleconv): Sequential(\n      (0): Conv2d(1024, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (2): ReLU(inplace=True)\n      (3): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (4): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (5): ReLU(inplace=True)\n    )\n  )\n  (up3): Decoder_up(\n    (up): Sequential(\n      (0): Upsample(scale_factor=2.0, mode='bilinear')\n      (1): DoubleConv(\n        (doubleconv): Sequential(\n          (0): Conv2d(512, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n          (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n          (2): ReLU(inplace=True)\n          (3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n          (4): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n          (5): ReLU(inplace=True)\n        )\n      )\n    )\n  )\n  (up_conv3): DoubleConv(\n    (doubleconv): Sequential(\n      (0): Conv2d(512, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (2): ReLU(inplace=True)\n      (3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (4): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (5): ReLU(inplace=True)\n    )\n  )\n  (up2): Decoder_up(\n    (up): Sequential(\n      (0): Upsample(scale_factor=2.0, mode='bilinear')\n      (1): DoubleConv(\n        (doubleconv): Sequential(\n          (0): Conv2d(256, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n          (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n          (2): ReLU(inplace=True)\n          (3): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n          (4): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n          (5): ReLU(inplace=True)\n        )\n      )\n    )\n  )\n  (up_conv2): DoubleConv(\n    (doubleconv): Sequential(\n      (0): Conv2d(256, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (2): ReLU(inplace=True)\n      (3): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (4): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (5): ReLU(inplace=True)\n    )\n  )\n  (up1): Decoder_up(\n    (up): Sequential(\n      (0): Upsample(scale_factor=2.0, mode='bilinear')\n      (1): DoubleConv(\n        (doubleconv): Sequential(\n          (0): Conv2d(128, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n          (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n          (2): ReLU(inplace=True)\n          (3): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n          (4): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n          (5): ReLU(inplace=True)\n        )\n      )\n    )\n  )\n  (up_conv1): DoubleConv(\n    (doubleconv): Sequential(\n      (0): Conv2d(128, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (2): ReLU(inplace=True)\n      (3): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (4): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (5): ReLU(inplace=True)\n    )\n  )\n  (outc): outConv(\n    (conv): Conv2d(64, 4, kernel_size=(1, 1), stride=(1, 1))\n  )\n)"
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = Self_Attention_Unet(6,4).to('cpu')\n",
    "model"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "53c8bfbebc07189a"
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv2d-1         [-1, 64, 256, 256]           3,456\n",
      "       BatchNorm2d-2         [-1, 64, 256, 256]             128\n",
      "              ReLU-3         [-1, 64, 256, 256]               0\n",
      "            Conv2d-4         [-1, 64, 256, 256]          36,864\n",
      "       BatchNorm2d-5         [-1, 64, 256, 256]             128\n",
      "              ReLU-6         [-1, 64, 256, 256]               0\n",
      "        DoubleConv-7         [-1, 64, 256, 256]               0\n",
      "         MaxPool2d-8        [-1, 128, 128, 128]               0\n",
      "              Down-9        [-1, 128, 128, 128]               0\n",
      "        MaxPool2d-10          [-1, 256, 64, 64]               0\n",
      "             Down-11          [-1, 256, 64, 64]               0\n",
      "        MaxPool2d-12          [-1, 512, 32, 32]               0\n",
      "             Down-13          [-1, 512, 32, 32]               0\n",
      "        MaxPool2d-14         [-1, 1024, 16, 16]               0\n",
      "             Down-15         [-1, 1024, 16, 16]               0\n",
      "           Conv2d-16           [-1, 32, 64, 64]           8,224\n",
      "           Conv2d-17           [-1, 32, 64, 64]           8,224\n",
      "           Conv2d-18          [-1, 256, 64, 64]          65,792\n",
      "    SelfAttention-19          [-1, 256, 64, 64]               0\n",
      "           Conv2d-20           [-1, 64, 32, 32]          32,832\n",
      "           Conv2d-21           [-1, 64, 32, 32]          32,832\n",
      "           Conv2d-22          [-1, 512, 32, 32]         262,656\n",
      "    SelfAttention-23          [-1, 512, 32, 32]               0\n",
      "         Upsample-24         [-1, 1024, 32, 32]               0\n",
      "           Conv2d-25          [-1, 512, 32, 32]       4,718,592\n",
      "      BatchNorm2d-26          [-1, 512, 32, 32]           1,024\n",
      "             ReLU-27          [-1, 512, 32, 32]               0\n",
      "           Conv2d-28          [-1, 512, 32, 32]       2,359,296\n",
      "      BatchNorm2d-29          [-1, 512, 32, 32]           1,024\n",
      "             ReLU-30          [-1, 512, 32, 32]               0\n",
      "       DoubleConv-31          [-1, 512, 32, 32]               0\n",
      "       Decoder_up-32          [-1, 512, 32, 32]               0\n",
      "           Conv2d-33          [-1, 512, 32, 32]       4,718,592\n",
      "      BatchNorm2d-34          [-1, 512, 32, 32]           1,024\n",
      "             ReLU-35          [-1, 512, 32, 32]               0\n",
      "           Conv2d-36          [-1, 512, 32, 32]       2,359,296\n",
      "      BatchNorm2d-37          [-1, 512, 32, 32]           1,024\n",
      "             ReLU-38          [-1, 512, 32, 32]               0\n",
      "       DoubleConv-39          [-1, 512, 32, 32]               0\n",
      "         Upsample-40          [-1, 512, 64, 64]               0\n",
      "           Conv2d-41          [-1, 256, 64, 64]       1,179,648\n",
      "      BatchNorm2d-42          [-1, 256, 64, 64]             512\n",
      "             ReLU-43          [-1, 256, 64, 64]               0\n",
      "           Conv2d-44          [-1, 256, 64, 64]         589,824\n",
      "      BatchNorm2d-45          [-1, 256, 64, 64]             512\n",
      "             ReLU-46          [-1, 256, 64, 64]               0\n",
      "       DoubleConv-47          [-1, 256, 64, 64]               0\n",
      "       Decoder_up-48          [-1, 256, 64, 64]               0\n",
      "           Conv2d-49          [-1, 256, 64, 64]       1,179,648\n",
      "      BatchNorm2d-50          [-1, 256, 64, 64]             512\n",
      "             ReLU-51          [-1, 256, 64, 64]               0\n",
      "           Conv2d-52          [-1, 256, 64, 64]         589,824\n",
      "      BatchNorm2d-53          [-1, 256, 64, 64]             512\n",
      "             ReLU-54          [-1, 256, 64, 64]               0\n",
      "       DoubleConv-55          [-1, 256, 64, 64]               0\n",
      "         Upsample-56        [-1, 256, 128, 128]               0\n",
      "           Conv2d-57        [-1, 128, 128, 128]         294,912\n",
      "      BatchNorm2d-58        [-1, 128, 128, 128]             256\n",
      "             ReLU-59        [-1, 128, 128, 128]               0\n",
      "           Conv2d-60        [-1, 128, 128, 128]         147,456\n",
      "      BatchNorm2d-61        [-1, 128, 128, 128]             256\n",
      "             ReLU-62        [-1, 128, 128, 128]               0\n",
      "       DoubleConv-63        [-1, 128, 128, 128]               0\n",
      "       Decoder_up-64        [-1, 128, 128, 128]               0\n",
      "           Conv2d-65        [-1, 128, 128, 128]         294,912\n",
      "      BatchNorm2d-66        [-1, 128, 128, 128]             256\n",
      "             ReLU-67        [-1, 128, 128, 128]               0\n",
      "           Conv2d-68        [-1, 128, 128, 128]         147,456\n",
      "      BatchNorm2d-69        [-1, 128, 128, 128]             256\n",
      "             ReLU-70        [-1, 128, 128, 128]               0\n",
      "       DoubleConv-71        [-1, 128, 128, 128]               0\n",
      "         Upsample-72        [-1, 128, 256, 256]               0\n",
      "           Conv2d-73         [-1, 64, 256, 256]          73,728\n",
      "      BatchNorm2d-74         [-1, 64, 256, 256]             128\n",
      "             ReLU-75         [-1, 64, 256, 256]               0\n",
      "           Conv2d-76         [-1, 64, 256, 256]          36,864\n",
      "      BatchNorm2d-77         [-1, 64, 256, 256]             128\n",
      "             ReLU-78         [-1, 64, 256, 256]               0\n",
      "       DoubleConv-79         [-1, 64, 256, 256]               0\n",
      "       Decoder_up-80         [-1, 64, 256, 256]               0\n",
      "           Conv2d-81         [-1, 64, 256, 256]          73,728\n",
      "      BatchNorm2d-82         [-1, 64, 256, 256]             128\n",
      "             ReLU-83         [-1, 64, 256, 256]               0\n",
      "           Conv2d-84         [-1, 64, 256, 256]          36,864\n",
      "      BatchNorm2d-85         [-1, 64, 256, 256]             128\n",
      "             ReLU-86         [-1, 64, 256, 256]               0\n",
      "       DoubleConv-87         [-1, 64, 256, 256]               0\n",
      "           Conv2d-88          [-1, 4, 256, 256]             260\n",
      "          outConv-89          [-1, 4, 256, 256]               0\n",
      "================================================================\n",
      "Total params: 19,259,716\n",
      "Trainable params: 19,259,716\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 1.50\n",
      "Forward/backward pass size (MB): 1335.00\n",
      "Params size (MB): 73.47\n",
      "Estimated Total Size (MB): 1409.97\n",
      "----------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "summary(model, input_size= (6,256,256))"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "f9c40c65bc162a7c"
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "outputs": [],
   "source": [
    "class Unet_with_attention_block(nn.Module): \n",
    "    def __init__(\n",
    "            self, \n",
    "            image_channels, \n",
    "            n_classes, \n",
    "            mid_layers = [64, 128, 256, 512, 1024],\n",
    "            bilinear = True      \n",
    "            ):\n",
    "        super().__init__()\n",
    "        \n",
    "        # Encoder \n",
    "        self.Conv1 = DoubleConv(in_channel= image_channels, out_channel= mid_layers[0])\n",
    "        self.Conv2 = Down(in_channel= mid_layers[0], out_channel= mid_layers[1])\n",
    "        self.Conv3 = Down(in_channel= mid_layers[1], out_channel= mid_layers[2])\n",
    "        self.Conv4 = Down(in_channel= mid_layers[2], out_channel= mid_layers[3])\n",
    "        self.Conv_code = Down(in_channel= mid_layers[3], out_channel= mid_layers[4])\n",
    "        \n",
    "        # decoder \n",
    "        # Upsampling including attention, then convolutional layer to reduce the size \n",
    "        # this is one block \n",
    "        self.up4 = Decoder_up(in_channel= mid_layers[4], out_channel= mid_layers[3])\n",
    "        self.att4 = Attention_block(encoder_channels= mid_layers[3], decoder_channels= mid_layers[3])\n",
    "        self.up_conv4 = DoubleConv(in_channel= mid_layers[4], out_channel= mid_layers[3])\n",
    "        \n",
    "        # second upsampling \n",
    "        self.up3 = Decoder_up(in_channel= mid_layers[3], out_channel= mid_layers[2])\n",
    "        self.att3 = Attention_block(encoder_channels= mid_layers[2], decoder_channels=mid_layers[2])\n",
    "        self.up_conv3 = DoubleConv(in_channel= mid_layers[3], out_channel=mid_layers[2])\n",
    "         \n",
    "        # Third upsampling \n",
    "        self.up2 = Decoder_up(in_channel= mid_layers[2], out_channel= mid_layers[1])\n",
    "        self.att2 = Attention_block(encoder_channels= mid_layers[1], decoder_channels=mid_layers[1])\n",
    "        self.up_conv2 = DoubleConv(in_channel= mid_layers[2], out_channel= mid_layers[1])\n",
    "        \n",
    "        # Fourth upsampling \n",
    "        self.up1 = Decoder_up(in_channel= mid_layers[1], out_channel= mid_layers[0])\n",
    "        self.att1 = Attention_block(encoder_channels= mid_layers[0], decoder_channels= mid_layers[0])\n",
    "        self.up_conv1 = DoubleConv(in_channel= mid_layers[1], out_channel= mid_layers[0])\n",
    "        \n",
    "        # final output convolutional block \n",
    "        self.outc= outConv(mid_layers[0], n_classes)\n",
    "        \n",
    "        \n",
    "    def forward(self, x):\n",
    "        # Encoder traversal\n",
    "        x1 = self.Conv1(x)\n",
    "        x2 = self.Conv2(x1)\n",
    "        x3 = self.Conv3(x2)\n",
    "        x4 = self.Conv4(x3)\n",
    "        x5 = self.Conv_code(x4)\n",
    "        \n",
    "        # Decoding and attention concat\n",
    "        # Upsample x5, attention w respect to x4 and d5 \n",
    "        # concat \n",
    "        \n",
    "        # first block\n",
    "        dec_out = self.up4(x5)\n",
    "        x4 = self.att4(dec_out, x4) # calculate attention block \n",
    "        dec_out = torch.cat((dec_out, x4), dim=1)\n",
    "        dec_out = self.up_conv4(dec_out)\n",
    "        \n",
    "        # second block \n",
    "        dec_out = self.up3(dec_out)\n",
    "        x3 = self.att3(dec_out, x3) # calculate attention block \n",
    "        dec_out = torch.cat((dec_out, x3), dim=1)\n",
    "        dec_out = self.up_conv3(dec_out)\n",
    "\n",
    "        # third block\n",
    "        dec_out = self.up2(dec_out)\n",
    "        x2 = self.att2(dec_out, x2) # calculate attention block \n",
    "        dec_out = torch.cat((dec_out, x2), dim=1)\n",
    "        dec_out = self.up_conv2(dec_out)\n",
    "        \n",
    "        # second block \n",
    "        dec_out = self.up1(dec_out)\n",
    "        x1 = self.att1(dec_out, x1) # calculate attention block \n",
    "        dec_out = torch.cat((dec_out, x1), dim=1)\n",
    "        dec_out = self.up_conv1(dec_out)\n",
    "\n",
    "        logits = self.outc(dec_out)\n",
    "        \n",
    "        return logits \n",
    "        \n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-08-19T15:47:12.237608Z",
     "start_time": "2025-08-19T15:47:12.230574Z"
    }
   },
   "id": "68ec18db94f5eae"
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "outputs": [
    {
     "data": {
      "text/plain": "Unet_with_attention_block(\n  (Conv1): DoubleConv(\n    (doubleconv): Sequential(\n      (0): Conv2d(6, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (2): ReLU(inplace=True)\n      (3): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (4): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (5): ReLU(inplace=True)\n    )\n  )\n  (Conv2): Down(\n    (maxpool_layer): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n  )\n  (Conv3): Down(\n    (maxpool_layer): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n  )\n  (Conv4): Down(\n    (maxpool_layer): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n  )\n  (Conv_code): Down(\n    (maxpool_layer): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n  )\n  (up4): Decoder_up(\n    (up): Sequential(\n      (0): Upsample(scale_factor=2.0, mode='bilinear')\n      (1): DoubleConv(\n        (doubleconv): Sequential(\n          (0): Conv2d(1024, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n          (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n          (2): ReLU(inplace=True)\n          (3): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n          (4): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n          (5): ReLU(inplace=True)\n        )\n      )\n    )\n  )\n  (att4): Attention_block(\n    (W_gate): Sequential(\n      (0): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1))\n      (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    )\n    (W_encoder): Sequential(\n      (0): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1))\n      (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    )\n    (psi): Sequential(\n      (0): Conv2d(256, 1, kernel_size=(1, 1), stride=(1, 1))\n      (1): Sigmoid()\n    )\n    (relu): ReLU(inplace=True)\n  )\n  (up_conv4): DoubleConv(\n    (doubleconv): Sequential(\n      (0): Conv2d(1024, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (2): ReLU(inplace=True)\n      (3): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (4): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (5): ReLU(inplace=True)\n    )\n  )\n  (up3): Decoder_up(\n    (up): Sequential(\n      (0): Upsample(scale_factor=2.0, mode='bilinear')\n      (1): DoubleConv(\n        (doubleconv): Sequential(\n          (0): Conv2d(512, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n          (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n          (2): ReLU(inplace=True)\n          (3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n          (4): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n          (5): ReLU(inplace=True)\n        )\n      )\n    )\n  )\n  (att3): Attention_block(\n    (W_gate): Sequential(\n      (0): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1))\n      (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    )\n    (W_encoder): Sequential(\n      (0): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1))\n      (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    )\n    (psi): Sequential(\n      (0): Conv2d(128, 1, kernel_size=(1, 1), stride=(1, 1))\n      (1): Sigmoid()\n    )\n    (relu): ReLU(inplace=True)\n  )\n  (up_conv3): DoubleConv(\n    (doubleconv): Sequential(\n      (0): Conv2d(512, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (2): ReLU(inplace=True)\n      (3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (4): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (5): ReLU(inplace=True)\n    )\n  )\n  (up2): Decoder_up(\n    (up): Sequential(\n      (0): Upsample(scale_factor=2.0, mode='bilinear')\n      (1): DoubleConv(\n        (doubleconv): Sequential(\n          (0): Conv2d(256, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n          (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n          (2): ReLU(inplace=True)\n          (3): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n          (4): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n          (5): ReLU(inplace=True)\n        )\n      )\n    )\n  )\n  (att2): Attention_block(\n    (W_gate): Sequential(\n      (0): Conv2d(128, 64, kernel_size=(1, 1), stride=(1, 1))\n      (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    )\n    (W_encoder): Sequential(\n      (0): Conv2d(128, 64, kernel_size=(1, 1), stride=(1, 1))\n      (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    )\n    (psi): Sequential(\n      (0): Conv2d(64, 1, kernel_size=(1, 1), stride=(1, 1))\n      (1): Sigmoid()\n    )\n    (relu): ReLU(inplace=True)\n  )\n  (up_conv2): DoubleConv(\n    (doubleconv): Sequential(\n      (0): Conv2d(256, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (2): ReLU(inplace=True)\n      (3): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (4): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (5): ReLU(inplace=True)\n    )\n  )\n  (up1): Decoder_up(\n    (up): Sequential(\n      (0): Upsample(scale_factor=2.0, mode='bilinear')\n      (1): DoubleConv(\n        (doubleconv): Sequential(\n          (0): Conv2d(128, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n          (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n          (2): ReLU(inplace=True)\n          (3): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n          (4): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n          (5): ReLU(inplace=True)\n        )\n      )\n    )\n  )\n  (att1): Attention_block(\n    (W_gate): Sequential(\n      (0): Conv2d(64, 32, kernel_size=(1, 1), stride=(1, 1))\n      (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    )\n    (W_encoder): Sequential(\n      (0): Conv2d(64, 32, kernel_size=(1, 1), stride=(1, 1))\n      (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    )\n    (psi): Sequential(\n      (0): Conv2d(32, 1, kernel_size=(1, 1), stride=(1, 1))\n      (1): Sigmoid()\n    )\n    (relu): ReLU(inplace=True)\n  )\n  (up_conv1): DoubleConv(\n    (doubleconv): Sequential(\n      (0): Conv2d(128, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (2): ReLU(inplace=True)\n      (3): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (4): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (5): ReLU(inplace=True)\n    )\n  )\n  (outc): outConv(\n    (conv): Conv2d(64, 5, kernel_size=(1, 1), stride=(1, 1))\n  )\n)"
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = Unet_with_attention_block(image_channels=6, n_classes=5)\n",
    "model "
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-08-19T15:47:13.328047Z",
     "start_time": "2025-08-19T15:47:13.255109Z"
    }
   },
   "id": "3048a1388b1b9b1d"
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv2d-1         [-1, 64, 256, 256]           3,456\n",
      "       BatchNorm2d-2         [-1, 64, 256, 256]             128\n",
      "              ReLU-3         [-1, 64, 256, 256]               0\n",
      "            Conv2d-4         [-1, 64, 256, 256]          36,864\n",
      "       BatchNorm2d-5         [-1, 64, 256, 256]             128\n",
      "              ReLU-6         [-1, 64, 256, 256]               0\n",
      "        DoubleConv-7         [-1, 64, 256, 256]               0\n",
      "         MaxPool2d-8        [-1, 128, 128, 128]               0\n",
      "              Down-9        [-1, 128, 128, 128]               0\n",
      "        MaxPool2d-10          [-1, 256, 64, 64]               0\n",
      "             Down-11          [-1, 256, 64, 64]               0\n",
      "        MaxPool2d-12          [-1, 512, 32, 32]               0\n",
      "             Down-13          [-1, 512, 32, 32]               0\n",
      "        MaxPool2d-14         [-1, 1024, 16, 16]               0\n",
      "             Down-15         [-1, 1024, 16, 16]               0\n",
      "         Upsample-16         [-1, 1024, 32, 32]               0\n",
      "           Conv2d-17          [-1, 512, 32, 32]       4,718,592\n",
      "      BatchNorm2d-18          [-1, 512, 32, 32]           1,024\n",
      "             ReLU-19          [-1, 512, 32, 32]               0\n",
      "           Conv2d-20          [-1, 512, 32, 32]       2,359,296\n",
      "      BatchNorm2d-21          [-1, 512, 32, 32]           1,024\n",
      "             ReLU-22          [-1, 512, 32, 32]               0\n",
      "       DoubleConv-23          [-1, 512, 32, 32]               0\n",
      "       Decoder_up-24          [-1, 512, 32, 32]               0\n",
      "           Conv2d-25          [-1, 256, 32, 32]         131,328\n",
      "      BatchNorm2d-26          [-1, 256, 32, 32]             512\n",
      "           Conv2d-27          [-1, 256, 32, 32]         131,328\n",
      "      BatchNorm2d-28          [-1, 256, 32, 32]             512\n",
      "             ReLU-29          [-1, 256, 32, 32]               0\n",
      "           Conv2d-30            [-1, 1, 32, 32]             257\n",
      "          Sigmoid-31            [-1, 1, 32, 32]               0\n",
      "  Attention_block-32          [-1, 512, 32, 32]               0\n",
      "           Conv2d-33          [-1, 512, 32, 32]       4,718,592\n",
      "      BatchNorm2d-34          [-1, 512, 32, 32]           1,024\n",
      "             ReLU-35          [-1, 512, 32, 32]               0\n",
      "           Conv2d-36          [-1, 512, 32, 32]       2,359,296\n",
      "      BatchNorm2d-37          [-1, 512, 32, 32]           1,024\n",
      "             ReLU-38          [-1, 512, 32, 32]               0\n",
      "       DoubleConv-39          [-1, 512, 32, 32]               0\n",
      "         Upsample-40          [-1, 512, 64, 64]               0\n",
      "           Conv2d-41          [-1, 256, 64, 64]       1,179,648\n",
      "      BatchNorm2d-42          [-1, 256, 64, 64]             512\n",
      "             ReLU-43          [-1, 256, 64, 64]               0\n",
      "           Conv2d-44          [-1, 256, 64, 64]         589,824\n",
      "      BatchNorm2d-45          [-1, 256, 64, 64]             512\n",
      "             ReLU-46          [-1, 256, 64, 64]               0\n",
      "       DoubleConv-47          [-1, 256, 64, 64]               0\n",
      "       Decoder_up-48          [-1, 256, 64, 64]               0\n",
      "           Conv2d-49          [-1, 128, 64, 64]          32,896\n",
      "      BatchNorm2d-50          [-1, 128, 64, 64]             256\n",
      "           Conv2d-51          [-1, 128, 64, 64]          32,896\n",
      "      BatchNorm2d-52          [-1, 128, 64, 64]             256\n",
      "             ReLU-53          [-1, 128, 64, 64]               0\n",
      "           Conv2d-54            [-1, 1, 64, 64]             129\n",
      "          Sigmoid-55            [-1, 1, 64, 64]               0\n",
      "  Attention_block-56          [-1, 256, 64, 64]               0\n",
      "           Conv2d-57          [-1, 256, 64, 64]       1,179,648\n",
      "      BatchNorm2d-58          [-1, 256, 64, 64]             512\n",
      "             ReLU-59          [-1, 256, 64, 64]               0\n",
      "           Conv2d-60          [-1, 256, 64, 64]         589,824\n",
      "      BatchNorm2d-61          [-1, 256, 64, 64]             512\n",
      "             ReLU-62          [-1, 256, 64, 64]               0\n",
      "       DoubleConv-63          [-1, 256, 64, 64]               0\n",
      "         Upsample-64        [-1, 256, 128, 128]               0\n",
      "           Conv2d-65        [-1, 128, 128, 128]         294,912\n",
      "      BatchNorm2d-66        [-1, 128, 128, 128]             256\n",
      "             ReLU-67        [-1, 128, 128, 128]               0\n",
      "           Conv2d-68        [-1, 128, 128, 128]         147,456\n",
      "      BatchNorm2d-69        [-1, 128, 128, 128]             256\n",
      "             ReLU-70        [-1, 128, 128, 128]               0\n",
      "       DoubleConv-71        [-1, 128, 128, 128]               0\n",
      "       Decoder_up-72        [-1, 128, 128, 128]               0\n",
      "           Conv2d-73         [-1, 64, 128, 128]           8,256\n",
      "      BatchNorm2d-74         [-1, 64, 128, 128]             128\n",
      "           Conv2d-75         [-1, 64, 128, 128]           8,256\n",
      "      BatchNorm2d-76         [-1, 64, 128, 128]             128\n",
      "             ReLU-77         [-1, 64, 128, 128]               0\n",
      "           Conv2d-78          [-1, 1, 128, 128]              65\n",
      "          Sigmoid-79          [-1, 1, 128, 128]               0\n",
      "  Attention_block-80        [-1, 128, 128, 128]               0\n",
      "           Conv2d-81        [-1, 128, 128, 128]         294,912\n",
      "      BatchNorm2d-82        [-1, 128, 128, 128]             256\n",
      "             ReLU-83        [-1, 128, 128, 128]               0\n",
      "           Conv2d-84        [-1, 128, 128, 128]         147,456\n",
      "      BatchNorm2d-85        [-1, 128, 128, 128]             256\n",
      "             ReLU-86        [-1, 128, 128, 128]               0\n",
      "       DoubleConv-87        [-1, 128, 128, 128]               0\n",
      "         Upsample-88        [-1, 128, 256, 256]               0\n",
      "           Conv2d-89         [-1, 64, 256, 256]          73,728\n",
      "      BatchNorm2d-90         [-1, 64, 256, 256]             128\n",
      "             ReLU-91         [-1, 64, 256, 256]               0\n",
      "           Conv2d-92         [-1, 64, 256, 256]          36,864\n",
      "      BatchNorm2d-93         [-1, 64, 256, 256]             128\n",
      "             ReLU-94         [-1, 64, 256, 256]               0\n",
      "       DoubleConv-95         [-1, 64, 256, 256]               0\n",
      "       Decoder_up-96         [-1, 64, 256, 256]               0\n",
      "           Conv2d-97         [-1, 32, 256, 256]           2,080\n",
      "      BatchNorm2d-98         [-1, 32, 256, 256]              64\n",
      "           Conv2d-99         [-1, 32, 256, 256]           2,080\n",
      "     BatchNorm2d-100         [-1, 32, 256, 256]              64\n",
      "            ReLU-101         [-1, 32, 256, 256]               0\n",
      "          Conv2d-102          [-1, 1, 256, 256]              33\n",
      "         Sigmoid-103          [-1, 1, 256, 256]               0\n",
      " Attention_block-104         [-1, 64, 256, 256]               0\n",
      "          Conv2d-105         [-1, 64, 256, 256]          73,728\n",
      "     BatchNorm2d-106         [-1, 64, 256, 256]             128\n",
      "            ReLU-107         [-1, 64, 256, 256]               0\n",
      "          Conv2d-108         [-1, 64, 256, 256]          36,864\n",
      "     BatchNorm2d-109         [-1, 64, 256, 256]             128\n",
      "            ReLU-110         [-1, 64, 256, 256]               0\n",
      "      DoubleConv-111         [-1, 64, 256, 256]               0\n",
      "          Conv2d-112          [-1, 5, 256, 256]             325\n",
      "         outConv-113          [-1, 5, 256, 256]               0\n",
      "================================================================\n",
      "Total params: 19,200,745\n",
      "Trainable params: 19,200,745\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 1.50\n",
      "Forward/backward pass size (MB): 1520.33\n",
      "Params size (MB): 73.25\n",
      "Estimated Total Size (MB): 1595.07\n",
      "----------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "summary(model, input_size=(6, 256,256))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-08-19T15:47:15.505915Z",
     "start_time": "2025-08-19T15:47:14.138952Z"
    }
   },
   "id": "6fa5a858b3d2c1ea"
  },
  {
   "cell_type": "markdown",
   "source": [
    "# HYBDRID MODEL \n",
    "- a model that incorporates self attention at the code level layers and Multi head attention at the top layers"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "f59986cb111c67ef"
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "outputs": [],
   "source": [
    "class Hybrid_Unet(nn.Module):\n",
    "    def __init__(\n",
    "            self,\n",
    "            image_channels,\n",
    "            n_classes,\n",
    "            mid_layers = [64,128, 256, 512, 1024],\n",
    "            bilinear= True,\n",
    "    ):\n",
    "        super().__init__()\n",
    "\n",
    "\n",
    "\n",
    "        # Encoder section of the network\n",
    "        \n",
    "        self.down1 = DoubleConv(image_channels, mid_layers[0])\n",
    "        self.down2 = Down(mid_layers[0], mid_layers[1])\n",
    "        self.down3 = Down(mid_layers[1], mid_layers[2])\n",
    "        self.down4 = Down(mid_layers[2], mid_layers[3])\n",
    "\n",
    "        # code block \n",
    "        self.down_code = Down(mid_layers[3], mid_layers[4])\n",
    "\n",
    "        # self attention \n",
    "        # ADD SELF ATTENTION for code layer \n",
    "\n",
    "        # decoder block\n",
    "        \n",
    "        # first level of upsampling \n",
    "        self.up4 = Decoder_up(mid_layers[4], mid_layers[3]) # code block \n",
    "        self.attention4 = SelfAttention(mid_layers[3]) # self attention\n",
    "        self.up_conv4 = DoubleConv(in_channel= mid_layers[4], out_channel= mid_layers[3])\n",
    "\n",
    "        # second level of upsampling\n",
    "        self.up3 = Decoder_up(mid_layers[3], mid_layers[2])\n",
    "        self.attention3 = SelfAttention(mid_layers[2]) # self attention\n",
    "        self.up_conv3 = DoubleConv(in_channel= mid_layers[3], out_channel= mid_layers[2])\n",
    "\n",
    "\n",
    "        # Third upsampling \n",
    "        self.up2 = Decoder_up(in_channel= mid_layers[2], out_channel= mid_layers[1])\n",
    "        self.att2 = Attention_block(encoder_channels= mid_layers[1], decoder_channels=mid_layers[1])\n",
    "        self.up_conv2 = DoubleConv(in_channel= mid_layers[2], out_channel= mid_layers[1])\n",
    "\n",
    "        # Fourth upsampling \n",
    "        self.up1 = Decoder_up(in_channel= mid_layers[1], out_channel= mid_layers[0])\n",
    "        self.att1 = Attention_block(encoder_channels= mid_layers[0], decoder_channels= mid_layers[0])\n",
    "        self.up_conv1 = DoubleConv(in_channel= mid_layers[1], out_channel= mid_layers[0])\n",
    "\n",
    "        \n",
    "        # outputlayers\n",
    "        self.outc = outConv(mid_layers[0], n_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # you cant create a seperate encoder, decoder function because you need the x1, x2 and so on values for attention calculation   \n",
    "        # encoder calculations \n",
    "        x1 = self.down1(x)\n",
    "        x2 = self.down2(x1)\n",
    "        x3 = self.down3(x2)\n",
    "        x4 = self.down4(x3)\n",
    "        x5 = self.down_code(x4)\n",
    "\n",
    "        # x5 is the code layer\n",
    "\n",
    "\n",
    "\n",
    "        # Decoding \n",
    "        # SELF ATTENTION LAYERS\n",
    "        # level four \n",
    "        dec_out = self.up4(x5) # code layer and the final layer of attention \n",
    "        v4 = self.attention4(x4) # attention\n",
    "        dec_out = torch.cat((dec_out,v4), dim=1)\n",
    "        dec_out = self.up_conv4(dec_out)\n",
    "        \n",
    "        # level 3\n",
    "        dec_out = self.up3(dec_out)\n",
    "        v3 = self.attention3(x3) \n",
    "        dec_out = torch.cat((dec_out,v3), dim=1)\n",
    "        dec_out = self.up_conv3(dec_out)\n",
    "        \n",
    "        # MULTI HEAD ATTENTION LAYERS \n",
    "        # Level 2 \n",
    "        dec_out = self.up2(dec_out)\n",
    "        x2 = self.att2(dec_out, x2) # calculate attention block \n",
    "        dec_out = torch.cat((dec_out, x2), dim=1)\n",
    "        dec_out = self.up_conv2(dec_out)\n",
    "        \n",
    "        # Level 1 \n",
    "        dec_out = self.up1(dec_out)\n",
    "        x1 = self.att1(dec_out, x1) # calculate attention block \n",
    "        dec_out = torch.cat((dec_out, x1), dim=1)\n",
    "        dec_out = self.up_conv1(dec_out)\n",
    "\n",
    "\n",
    "        # calculate output\n",
    "        logits = self.outc(dec_out)\n",
    "        return logits\n",
    "        \n",
    "        "
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-08-19T18:03:14.037231Z",
     "start_time": "2025-08-19T18:03:14.028983Z"
    }
   },
   "id": "25ed2dc8dbbd902d"
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "outputs": [
    {
     "data": {
      "text/plain": "Hybrid_Unet(\n  (down1): DoubleConv(\n    (doubleconv): Sequential(\n      (0): Conv2d(6, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (2): ReLU(inplace=True)\n      (3): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (4): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (5): ReLU(inplace=True)\n    )\n  )\n  (down2): Down(\n    (maxpool_layer): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n  )\n  (down3): Down(\n    (maxpool_layer): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n  )\n  (down4): Down(\n    (maxpool_layer): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n  )\n  (down_code): Down(\n    (maxpool_layer): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n  )\n  (up4): Decoder_up(\n    (up): Sequential(\n      (0): Upsample(scale_factor=2.0, mode='bilinear')\n      (1): DoubleConv(\n        (doubleconv): Sequential(\n          (0): Conv2d(1024, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n          (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n          (2): ReLU(inplace=True)\n          (3): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n          (4): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n          (5): ReLU(inplace=True)\n        )\n      )\n    )\n  )\n  (attention4): SelfAttention(\n    (query_conv): Conv2d(512, 64, kernel_size=(1, 1), stride=(1, 1))\n    (key_conv): Conv2d(512, 64, kernel_size=(1, 1), stride=(1, 1))\n    (value_conv): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1))\n  )\n  (up_conv4): DoubleConv(\n    (doubleconv): Sequential(\n      (0): Conv2d(1024, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (2): ReLU(inplace=True)\n      (3): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (4): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (5): ReLU(inplace=True)\n    )\n  )\n  (up3): Decoder_up(\n    (up): Sequential(\n      (0): Upsample(scale_factor=2.0, mode='bilinear')\n      (1): DoubleConv(\n        (doubleconv): Sequential(\n          (0): Conv2d(512, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n          (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n          (2): ReLU(inplace=True)\n          (3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n          (4): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n          (5): ReLU(inplace=True)\n        )\n      )\n    )\n  )\n  (attention3): SelfAttention(\n    (query_conv): Conv2d(256, 32, kernel_size=(1, 1), stride=(1, 1))\n    (key_conv): Conv2d(256, 32, kernel_size=(1, 1), stride=(1, 1))\n    (value_conv): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))\n  )\n  (up_conv3): DoubleConv(\n    (doubleconv): Sequential(\n      (0): Conv2d(512, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (2): ReLU(inplace=True)\n      (3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (4): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (5): ReLU(inplace=True)\n    )\n  )\n  (up2): Decoder_up(\n    (up): Sequential(\n      (0): Upsample(scale_factor=2.0, mode='bilinear')\n      (1): DoubleConv(\n        (doubleconv): Sequential(\n          (0): Conv2d(256, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n          (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n          (2): ReLU(inplace=True)\n          (3): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n          (4): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n          (5): ReLU(inplace=True)\n        )\n      )\n    )\n  )\n  (att2): Attention_block(\n    (W_gate): Sequential(\n      (0): Conv2d(128, 64, kernel_size=(1, 1), stride=(1, 1))\n      (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    )\n    (W_encoder): Sequential(\n      (0): Conv2d(128, 64, kernel_size=(1, 1), stride=(1, 1))\n      (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    )\n    (psi): Sequential(\n      (0): Conv2d(64, 1, kernel_size=(1, 1), stride=(1, 1))\n      (1): Sigmoid()\n    )\n    (relu): ReLU(inplace=True)\n  )\n  (up_conv2): DoubleConv(\n    (doubleconv): Sequential(\n      (0): Conv2d(256, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (2): ReLU(inplace=True)\n      (3): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (4): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (5): ReLU(inplace=True)\n    )\n  )\n  (up1): Decoder_up(\n    (up): Sequential(\n      (0): Upsample(scale_factor=2.0, mode='bilinear')\n      (1): DoubleConv(\n        (doubleconv): Sequential(\n          (0): Conv2d(128, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n          (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n          (2): ReLU(inplace=True)\n          (3): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n          (4): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n          (5): ReLU(inplace=True)\n        )\n      )\n    )\n  )\n  (att1): Attention_block(\n    (W_gate): Sequential(\n      (0): Conv2d(64, 32, kernel_size=(1, 1), stride=(1, 1))\n      (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    )\n    (W_encoder): Sequential(\n      (0): Conv2d(64, 32, kernel_size=(1, 1), stride=(1, 1))\n      (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    )\n    (psi): Sequential(\n      (0): Conv2d(32, 1, kernel_size=(1, 1), stride=(1, 1))\n      (1): Sigmoid()\n    )\n    (relu): ReLU(inplace=True)\n  )\n  (up_conv1): DoubleConv(\n    (doubleconv): Sequential(\n      (0): Conv2d(128, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (2): ReLU(inplace=True)\n      (3): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (4): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (5): ReLU(inplace=True)\n    )\n  )\n  (outc): outConv(\n    (conv): Conv2d(64, 5, kernel_size=(1, 1), stride=(1, 1))\n  )\n)"
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = Hybrid_Unet(6,5)\n",
    "model"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-08-19T18:03:14.658294Z",
     "start_time": "2025-08-19T18:03:14.654316Z"
    }
   },
   "id": "f95681400e1a88c0"
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv2d-1         [-1, 64, 256, 256]           3,456\n",
      "       BatchNorm2d-2         [-1, 64, 256, 256]             128\n",
      "              ReLU-3         [-1, 64, 256, 256]               0\n",
      "            Conv2d-4         [-1, 64, 256, 256]          36,864\n",
      "       BatchNorm2d-5         [-1, 64, 256, 256]             128\n",
      "              ReLU-6         [-1, 64, 256, 256]               0\n",
      "        DoubleConv-7         [-1, 64, 256, 256]               0\n",
      "         MaxPool2d-8        [-1, 128, 128, 128]               0\n",
      "              Down-9        [-1, 128, 128, 128]               0\n",
      "        MaxPool2d-10          [-1, 256, 64, 64]               0\n",
      "             Down-11          [-1, 256, 64, 64]               0\n",
      "        MaxPool2d-12          [-1, 512, 32, 32]               0\n",
      "             Down-13          [-1, 512, 32, 32]               0\n",
      "        MaxPool2d-14         [-1, 1024, 16, 16]               0\n",
      "             Down-15         [-1, 1024, 16, 16]               0\n",
      "         Upsample-16         [-1, 1024, 32, 32]               0\n",
      "           Conv2d-17          [-1, 512, 32, 32]       4,718,592\n",
      "      BatchNorm2d-18          [-1, 512, 32, 32]           1,024\n",
      "             ReLU-19          [-1, 512, 32, 32]               0\n",
      "           Conv2d-20          [-1, 512, 32, 32]       2,359,296\n",
      "      BatchNorm2d-21          [-1, 512, 32, 32]           1,024\n",
      "             ReLU-22          [-1, 512, 32, 32]               0\n",
      "       DoubleConv-23          [-1, 512, 32, 32]               0\n",
      "       Decoder_up-24          [-1, 512, 32, 32]               0\n",
      "           Conv2d-25           [-1, 64, 32, 32]          32,832\n",
      "           Conv2d-26           [-1, 64, 32, 32]          32,832\n",
      "           Conv2d-27          [-1, 512, 32, 32]         262,656\n",
      "    SelfAttention-28          [-1, 512, 32, 32]               0\n",
      "           Conv2d-29          [-1, 512, 32, 32]       4,718,592\n",
      "      BatchNorm2d-30          [-1, 512, 32, 32]           1,024\n",
      "             ReLU-31          [-1, 512, 32, 32]               0\n",
      "           Conv2d-32          [-1, 512, 32, 32]       2,359,296\n",
      "      BatchNorm2d-33          [-1, 512, 32, 32]           1,024\n",
      "             ReLU-34          [-1, 512, 32, 32]               0\n",
      "       DoubleConv-35          [-1, 512, 32, 32]               0\n",
      "         Upsample-36          [-1, 512, 64, 64]               0\n",
      "           Conv2d-37          [-1, 256, 64, 64]       1,179,648\n",
      "      BatchNorm2d-38          [-1, 256, 64, 64]             512\n",
      "             ReLU-39          [-1, 256, 64, 64]               0\n",
      "           Conv2d-40          [-1, 256, 64, 64]         589,824\n",
      "      BatchNorm2d-41          [-1, 256, 64, 64]             512\n",
      "             ReLU-42          [-1, 256, 64, 64]               0\n",
      "       DoubleConv-43          [-1, 256, 64, 64]               0\n",
      "       Decoder_up-44          [-1, 256, 64, 64]               0\n",
      "           Conv2d-45           [-1, 32, 64, 64]           8,224\n",
      "           Conv2d-46           [-1, 32, 64, 64]           8,224\n",
      "           Conv2d-47          [-1, 256, 64, 64]          65,792\n",
      "    SelfAttention-48          [-1, 256, 64, 64]               0\n",
      "           Conv2d-49          [-1, 256, 64, 64]       1,179,648\n",
      "      BatchNorm2d-50          [-1, 256, 64, 64]             512\n",
      "             ReLU-51          [-1, 256, 64, 64]               0\n",
      "           Conv2d-52          [-1, 256, 64, 64]         589,824\n",
      "      BatchNorm2d-53          [-1, 256, 64, 64]             512\n",
      "             ReLU-54          [-1, 256, 64, 64]               0\n",
      "       DoubleConv-55          [-1, 256, 64, 64]               0\n",
      "         Upsample-56        [-1, 256, 128, 128]               0\n",
      "           Conv2d-57        [-1, 128, 128, 128]         294,912\n",
      "      BatchNorm2d-58        [-1, 128, 128, 128]             256\n",
      "             ReLU-59        [-1, 128, 128, 128]               0\n",
      "           Conv2d-60        [-1, 128, 128, 128]         147,456\n",
      "      BatchNorm2d-61        [-1, 128, 128, 128]             256\n",
      "             ReLU-62        [-1, 128, 128, 128]               0\n",
      "       DoubleConv-63        [-1, 128, 128, 128]               0\n",
      "       Decoder_up-64        [-1, 128, 128, 128]               0\n",
      "           Conv2d-65         [-1, 64, 128, 128]           8,256\n",
      "      BatchNorm2d-66         [-1, 64, 128, 128]             128\n",
      "           Conv2d-67         [-1, 64, 128, 128]           8,256\n",
      "      BatchNorm2d-68         [-1, 64, 128, 128]             128\n",
      "             ReLU-69         [-1, 64, 128, 128]               0\n",
      "           Conv2d-70          [-1, 1, 128, 128]              65\n",
      "          Sigmoid-71          [-1, 1, 128, 128]               0\n",
      "  Attention_block-72        [-1, 128, 128, 128]               0\n",
      "           Conv2d-73        [-1, 128, 128, 128]         294,912\n",
      "      BatchNorm2d-74        [-1, 128, 128, 128]             256\n",
      "             ReLU-75        [-1, 128, 128, 128]               0\n",
      "           Conv2d-76        [-1, 128, 128, 128]         147,456\n",
      "      BatchNorm2d-77        [-1, 128, 128, 128]             256\n",
      "             ReLU-78        [-1, 128, 128, 128]               0\n",
      "       DoubleConv-79        [-1, 128, 128, 128]               0\n",
      "         Upsample-80        [-1, 128, 256, 256]               0\n",
      "           Conv2d-81         [-1, 64, 256, 256]          73,728\n",
      "      BatchNorm2d-82         [-1, 64, 256, 256]             128\n",
      "             ReLU-83         [-1, 64, 256, 256]               0\n",
      "           Conv2d-84         [-1, 64, 256, 256]          36,864\n",
      "      BatchNorm2d-85         [-1, 64, 256, 256]             128\n",
      "             ReLU-86         [-1, 64, 256, 256]               0\n",
      "       DoubleConv-87         [-1, 64, 256, 256]               0\n",
      "       Decoder_up-88         [-1, 64, 256, 256]               0\n",
      "           Conv2d-89         [-1, 32, 256, 256]           2,080\n",
      "      BatchNorm2d-90         [-1, 32, 256, 256]              64\n",
      "           Conv2d-91         [-1, 32, 256, 256]           2,080\n",
      "      BatchNorm2d-92         [-1, 32, 256, 256]              64\n",
      "             ReLU-93         [-1, 32, 256, 256]               0\n",
      "           Conv2d-94          [-1, 1, 256, 256]              33\n",
      "          Sigmoid-95          [-1, 1, 256, 256]               0\n",
      "  Attention_block-96         [-1, 64, 256, 256]               0\n",
      "           Conv2d-97         [-1, 64, 256, 256]          73,728\n",
      "      BatchNorm2d-98         [-1, 64, 256, 256]             128\n",
      "             ReLU-99         [-1, 64, 256, 256]               0\n",
      "          Conv2d-100         [-1, 64, 256, 256]          36,864\n",
      "     BatchNorm2d-101         [-1, 64, 256, 256]             128\n",
      "            ReLU-102         [-1, 64, 256, 256]               0\n",
      "      DoubleConv-103         [-1, 64, 256, 256]               0\n",
      "          Conv2d-104          [-1, 5, 256, 256]             325\n",
      "         outConv-105          [-1, 5, 256, 256]               0\n",
      "================================================================\n",
      "Total params: 19,280,935\n",
      "Trainable params: 19,280,935\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 1.50\n",
      "Forward/backward pass size (MB): 1505.25\n",
      "Params size (MB): 73.55\n",
      "Estimated Total Size (MB): 1580.30\n",
      "----------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "summary(model, input_size=(6,256,256))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-08-19T18:03:27.289075Z",
     "start_time": "2025-08-19T18:03:25.717575Z"
    }
   },
   "id": "7c0da14f0b2e3c38"
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "semanticsegmentation",
   "language": "python",
   "display_name": "Python (semanticsegmentation)"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
